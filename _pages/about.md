---
permalink: /
title: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
<div class="about-text">

I am a Ph.D. student at **PNU** in the [Visual Intelligence and Perception Lab](https://pnu-viplab.github.io/) advised by Prof. [Jinsun Park](https://zzangjinsun.github.io/). I am a recipient of the Best Poster Award at **2025 ICRA TIRO workshop**. I conducted research internship at STARS Team, **INRIA** with Prof. [Francois Bremond](https://www-sop.inria.fr/members/Francois.Bremond).
My research focuses on computer vision, particularly in the field of depth perception with multi-sensor fusion and video understanding.
</div>

---

# Publications
---

<div class="pub-entry">
  <img src="/images/CAR-Stereo_compress.gif" class="pub-img">

  <div class="pub-text">
    <strong>CAR-Stereo: Confidence-aware Adaptive Disparity Refinement for Real-time Stereo Matching</strong><br>
    Chanil Park, <strong>Janghyun Kim</strong>, Minseong Kweon, and Jinsun Park<br>
    <em>IEEE Robotics and Automation Letters (RA-L), 2025</em><br>
    <a href="https://ieeexplore.ieee.org/abstract/document/11260640">[Paper]</a>
  </div>
</div>


<div class="pub-entry">
  <img src="/images/BACGCN.png" class="pub-img">

  <div class="pub-text">
    <strong>BAC-GCN: Background-Aware CLIP-GCN Framework for Unsupervised Multi-Label Classification</strong><br>
    Yonghyeon Jo, <strong>Janghyun Kim</strong>, and Jinsun Park<br>
    <em>ACM International Conference on Multimedia (ACM MM), 2025</em><br>
    <a href="https://dl.acm.org/doi/abs/10.1145/3746027.3755253">[Paper]</a>
  </div>
</div>


<div class="pub-entry">
  <img src="/images/2024_ACCV.png" class="pub-img">

  <div class="pub-text">
    <strong>Exploiting Cross-modal Cost Volume for Multi-sensor Depth Estimation</strong><br>
    <strong>Janghyun Kim</strong>, Ukcheol Shin, Seokyong Heo, and Jinsun Park<br>
    <em>Asian Conference on Computer Vision (ACCV), 2024</em><br>
    <a href="https://openaccess.thecvf.com/content/ACCV2024/html/Kim_Exploiting_Cross-modal_Cost_Volume_for_Multi-sensor_Depth_Estimation_ACCV_2024_paper.html">[Paper]</a>
  </div>
</div>


<div class="pub-entry">
  <img src="/images/ADnet.png" class="pub-img">

  <div class="pub-text">
    <strong>ADNet: Non-Local Affinity Distillation Network for Lightweight Depth Completion with Guidance from Missing LiDAR Points</strong><br>
    <strong>Janghyun Kim</strong>, Jeonghyun Noh, Mingyu Jeong, Wonju Lee, Yeonchool Park, and Jinsun Park<br>
    <em>IEEE Robotics and Automation Letters (RA-L), 2024</em><br>
    <a href="https://ieeexplore.ieee.org/abstract/document/10598333">[Paper]</a>
  </div>
</div>


## Under Review

<div class="pub-entry">
  <img src="/images/2025_CoPS.gif" class="pub-img">

  <div class="pub-text">
    <strong>All-day Depth Completion via Thermal-LiDAR Fusion</strong><br>
    <strong>Janghyun Kim</strong>, Minseong Kweon, and Jinsun Park<br>
    <em>arXiv, 2025</em><br>
    <a href="https://arxiv.org/abs/2504.02356">[Paper]</a>
  </div>
</div>


<div class="pub-entry">
  <img src="/images/MrGS.png" class="pub-img">

  <div class="pub-text">
    <strong>MrGS: Multi-modal Radiance Fields with 3D Gaussian Splatting for RGB-Thermal Novel View Synthesis</strong><br>
    Minseong Kweon<sup>†</sup>, <strong>Janghyun Kim</strong><sup>†</sup>, and Jinsun Park<br>
    <em>arXiv, 2025</em> (<sup>†</sup>Equal contribution)<br>
    <a href="https://arxiv.org/abs/2511.22997">[Paper]</a>
  </div>
</div>


# Awards
---
**Best Poster Award**, 'Thermal Infrared in Robotics' workshop @ ICRA 2025, May 2025

**Fellowship for Grad Student**, Pusan National Univerrsity, May 2024
